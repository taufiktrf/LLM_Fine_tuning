# Meta Llama 2 7B Language Model Fine-Tuning Project

## Overview

This repository documents the fine-tuning process of the Meta Llama 2 7B large language model, focusing on the financial domain. The project aims to enhance the model's understanding and generation capabilities specific to financial text data. The entire process, from fine-tuning the model to deploying it, is facilitated using various AWS services. Detailed steps and explanations are provided within the Markdown cells of Jupyter notebooks. This project is undertaken as part of the "Introducing Generative AI with AWS" course available on Coursera.

## Key Tasks

- Fine-tuning the Meta Llama 2 7B model using a financial text dataset.
- Deploying the fine-tuned model for practical use.
- Evaluating the model's text generation and domain knowledge capabilities before and after fine-tuning.

## Project Structure

- **Notebooks:** Contains Jupyter notebooks detailing each stage of the project, including data preprocessing, model fine-tuning, deployment, and evaluation.
- **Data:** Houses the financial text dataset used for fine-tuning the model.
- **Documentation:** Additional documentation or resources related to the project.
- **Models:** Stores the fine-tuned model and any associated artifacts.

## Acknowledgments

Special thanks to the instructors and contributors of the "Introducing Generative AI with AWS" course on Udacity.
